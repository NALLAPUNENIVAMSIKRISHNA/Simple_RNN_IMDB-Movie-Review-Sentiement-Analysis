{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Word Embedding"
      ],
      "metadata": {
        "id": "cA8eTlHFmnkk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding.ipynb"
      ],
      "metadata": {
        "id": "z3Y9_X4vYg9e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vrGP4Sjya1tg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Sentences\n",
        "sent=[\n",
        "    'the glass of milk',\n",
        "    'the glass of juice',\n",
        "    'the cup of tea',\n",
        "    'I am a good boy',\n",
        "    'I am a good developer',\n",
        "    'understand the meaning of words',\n",
        "    'your health is good'\n",
        "]"
      ],
      "metadata": {
        "id": "5kbp_4_Rea62"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuqW-FjMe4qC",
        "outputId": "ccf027e0-135a-4080-d90e-39fe60975148"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good developer',\n",
              " 'understand the meaning of words',\n",
              " 'your health is good']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Define the vocabulary size\n",
        "voc_size=10000"
      ],
      "metadata": {
        "id": "QoxeTu7De8mW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## One hot representation for every word\n",
        "one_hot_repr=[one_hot(words,voc_size)for words in sent]\n",
        "one_hot_repr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uw8keJefCi_",
        "outputId": "b9e13277-30a6-42de-ab04-7cd6cccc8ade"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1404, 9383, 5472, 6860],\n",
              " [1404, 9383, 5472, 7898],\n",
              " [1404, 6438, 5472, 5937],\n",
              " [1120, 8206, 404, 3295, 7846],\n",
              " [1120, 8206, 404, 3295, 4269],\n",
              " [8394, 1404, 343, 5472, 3030],\n",
              " [5762, 7816, 9820, 3295]]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## word embedding representation\n",
        "\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "1DTdKhl9fZTN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "B5c4vskThaEu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_length=8\n",
        "embedded_docs=pad_sequences(one_hot_repr,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ],
      "metadata": {
        "id": "dAUA9h-ehgcH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be815fed-d862-418a-e9dc-461c3a4efbc1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0 1404 9383 5472 6860]\n",
            " [   0    0    0    0 1404 9383 5472 7898]\n",
            " [   0    0    0    0 1404 6438 5472 5937]\n",
            " [   0    0    0 1120 8206  404 3295 7846]\n",
            " [   0    0    0 1120 8206  404 3295 4269]\n",
            " [   0    0    0 8394 1404  343 5472 3030]\n",
            " [   0    0    0    0 5762 7816 9820 3295]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature representation\n",
        "dim=10"
      ],
      "metadata": {
        "id": "W6RVgqusiWfU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
        "model.compile('adam','mse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWmQL4BEi6Sc",
        "outputId": "847012ce-f4ad-46d2-99f9-61e8ae111832"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "axwjNwvljKWA",
        "outputId": "70238b30-6945-4472-963f-6b1a20003bbc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(embedded_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyEvzgiujOGQ",
        "outputId": "74160a6b-dd1b-4e02-b0c5-be0f71600479"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [-0.0213981 ,  0.04520601,  0.04399427, -0.04818806,\n",
              "         -0.01655736, -0.03544904,  0.02236592, -0.01081378,\n",
              "         -0.02183552, -0.02804511],\n",
              "        [-0.02798542, -0.02354494,  0.00742956,  0.0455637 ,\n",
              "         -0.0002737 ,  0.04357047, -0.04469417, -0.01977613,\n",
              "         -0.04299939, -0.01013579],\n",
              "        [-0.02889723,  0.04261513,  0.00986449, -0.04928665,\n",
              "          0.00655514,  0.00917619,  0.04994521, -0.01572736,\n",
              "          0.02472827,  0.00780456],\n",
              "        [ 0.04937917,  0.0314832 , -0.04543649, -0.03543836,\n",
              "          0.01001024, -0.01499469,  0.03282479, -0.02487421,\n",
              "          0.00815988, -0.00212198]],\n",
              "\n",
              "       [[ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [-0.0213981 ,  0.04520601,  0.04399427, -0.04818806,\n",
              "         -0.01655736, -0.03544904,  0.02236592, -0.01081378,\n",
              "         -0.02183552, -0.02804511],\n",
              "        [-0.02798542, -0.02354494,  0.00742956,  0.0455637 ,\n",
              "         -0.0002737 ,  0.04357047, -0.04469417, -0.01977613,\n",
              "         -0.04299939, -0.01013579],\n",
              "        [-0.02889723,  0.04261513,  0.00986449, -0.04928665,\n",
              "          0.00655514,  0.00917619,  0.04994521, -0.01572736,\n",
              "          0.02472827,  0.00780456],\n",
              "        [-0.03466427, -0.04622963,  0.00625871,  0.01155972,\n",
              "         -0.04581659, -0.04537145, -0.02565997,  0.0066474 ,\n",
              "          0.01444155,  0.04539046]],\n",
              "\n",
              "       [[ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [-0.0213981 ,  0.04520601,  0.04399427, -0.04818806,\n",
              "         -0.01655736, -0.03544904,  0.02236592, -0.01081378,\n",
              "         -0.02183552, -0.02804511],\n",
              "        [-0.00260077, -0.04595472, -0.02656752, -0.01549441,\n",
              "         -0.0203405 ,  0.04900548,  0.04290129, -0.02777276,\n",
              "          0.03368206,  0.00314384],\n",
              "        [-0.02889723,  0.04261513,  0.00986449, -0.04928665,\n",
              "          0.00655514,  0.00917619,  0.04994521, -0.01572736,\n",
              "          0.02472827,  0.00780456],\n",
              "        [ 0.03586103, -0.04966141, -0.04267714,  0.02780122,\n",
              "         -0.00301173, -0.00885874,  0.03606429,  0.03508859,\n",
              "          0.03556259,  0.02046963]],\n",
              "\n",
              "       [[ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [-0.02147141, -0.02231063,  0.04517579, -0.01150145,\n",
              "          0.01339543, -0.03735996, -0.02773039,  0.00347042,\n",
              "         -0.04660423,  0.00606947],\n",
              "        [ 0.02640225,  0.01975229, -0.00496911,  0.04401047,\n",
              "          0.03029856,  0.02349261,  0.02105569,  0.03162113,\n",
              "          0.04317624, -0.04200202],\n",
              "        [-0.04058939,  0.00251578, -0.01103141,  0.0343272 ,\n",
              "          0.04017745,  0.04771585,  0.0090281 , -0.01549502,\n",
              "          0.03742126,  0.00239502],\n",
              "        [-0.04196218,  0.04572083, -0.03967341,  0.00878163,\n",
              "          0.02398657,  0.03969736,  0.01907791, -0.04276074,\n",
              "          0.04363969,  0.02539026],\n",
              "        [-0.04592311, -0.04622135, -0.01861329,  0.03600473,\n",
              "          0.03793771,  0.01633452, -0.02662106, -0.03164847,\n",
              "          0.0451966 ,  0.02650649]],\n",
              "\n",
              "       [[ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [-0.02147141, -0.02231063,  0.04517579, -0.01150145,\n",
              "          0.01339543, -0.03735996, -0.02773039,  0.00347042,\n",
              "         -0.04660423,  0.00606947],\n",
              "        [ 0.02640225,  0.01975229, -0.00496911,  0.04401047,\n",
              "          0.03029856,  0.02349261,  0.02105569,  0.03162113,\n",
              "          0.04317624, -0.04200202],\n",
              "        [-0.04058939,  0.00251578, -0.01103141,  0.0343272 ,\n",
              "          0.04017745,  0.04771585,  0.0090281 , -0.01549502,\n",
              "          0.03742126,  0.00239502],\n",
              "        [-0.04196218,  0.04572083, -0.03967341,  0.00878163,\n",
              "          0.02398657,  0.03969736,  0.01907791, -0.04276074,\n",
              "          0.04363969,  0.02539026],\n",
              "        [ 0.02776202, -0.00820154, -0.02392923, -0.04569058,\n",
              "          0.02349005, -0.00025945,  0.00124849,  0.01735291,\n",
              "          0.01033438, -0.02862073]],\n",
              "\n",
              "       [[ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [-0.04494457,  0.03082737, -0.03448813, -0.02164881,\n",
              "          0.03861983, -0.02511326, -0.00492301,  0.04633642,\n",
              "         -0.04285252, -0.02779956],\n",
              "        [-0.0213981 ,  0.04520601,  0.04399427, -0.04818806,\n",
              "         -0.01655736, -0.03544904,  0.02236592, -0.01081378,\n",
              "         -0.02183552, -0.02804511],\n",
              "        [-0.01729064, -0.02288629,  0.02071438,  0.0022908 ,\n",
              "          0.00932239, -0.00562324, -0.01781149, -0.03060662,\n",
              "          0.02491156,  0.03487137],\n",
              "        [-0.02889723,  0.04261513,  0.00986449, -0.04928665,\n",
              "          0.00655514,  0.00917619,  0.04994521, -0.01572736,\n",
              "          0.02472827,  0.00780456],\n",
              "        [-0.01523167, -0.03673957, -0.03027996,  0.02446805,\n",
              "         -0.00443499,  0.03681536,  0.03613821,  0.04875972,\n",
              "          0.04973233, -0.04830054]],\n",
              "\n",
              "       [[ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.02646026,  0.01281967,  0.03226331,  0.03313876,\n",
              "          0.01709067, -0.02109617,  0.01845534,  0.00836947,\n",
              "         -0.02758033, -0.00267068],\n",
              "        [ 0.01831956,  0.02367214, -0.03885046, -0.02823935,\n",
              "         -0.03760214, -0.01960059, -0.01409823,  0.01917702,\n",
              "         -0.04855767, -0.0239092 ],\n",
              "        [-0.03672942, -0.02951304,  0.03542949,  0.02014523,\n",
              "         -0.01004946, -0.00793356, -0.01872728,  0.00932948,\n",
              "         -0.04921667,  0.00051192],\n",
              "        [-0.01140283, -0.03318242,  0.00891048, -0.03489683,\n",
              "          0.02309561, -0.04665546,  0.03051612,  0.03973078,\n",
              "          0.02280622,  0.02529367],\n",
              "        [-0.04196218,  0.04572083, -0.03967341,  0.00878163,\n",
              "          0.02398657,  0.03969736,  0.01907791, -0.04276074,\n",
              "          0.04363969,  0.02539026]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4LM-S9lkL3i",
        "outputId": "d25e984e-eb0e-4ee1-ffd8-bb5fcf7d07c1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0, 1404, 9383, 5472, 6860], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**End to end DL project with Simple RNN**"
      ],
      "metadata": {
        "id": "sSNG9jRzol1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,SimpleRNN,Dense"
      ],
      "metadata": {
        "id": "Q94_8KWfo0wX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load the IMDB Dataset\n",
        "\n",
        "max_features=10000 # vocabulary size\n",
        "(X_train,y_train),(X_test,y_test)=imdb.load_data(num_words=max_features)\n",
        "\n",
        "# print the shape of data\n",
        "print(f'Training data shape: {X_train.shape}, Training labels shape : {y_train.shape}')\n",
        "print(f'Testing data shape: {X_test.shape}, Testing labels shape : {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6S4b7dEo4s5",
        "outputId": "81a892b6-8bf9-457f-d30b-972700809fa2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training data shape: (25000,), Training labels shape : (25000,)\n",
            "Testing data shape: (25000,), Testing labels shape : (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0],y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CySue2y3pLEx",
        "outputId": "8704493d-e6e4-41b8-ea1a-29fef48ff0ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1,\n",
              "  14,\n",
              "  22,\n",
              "  16,\n",
              "  43,\n",
              "  530,\n",
              "  973,\n",
              "  1622,\n",
              "  1385,\n",
              "  65,\n",
              "  458,\n",
              "  4468,\n",
              "  66,\n",
              "  3941,\n",
              "  4,\n",
              "  173,\n",
              "  36,\n",
              "  256,\n",
              "  5,\n",
              "  25,\n",
              "  100,\n",
              "  43,\n",
              "  838,\n",
              "  112,\n",
              "  50,\n",
              "  670,\n",
              "  2,\n",
              "  9,\n",
              "  35,\n",
              "  480,\n",
              "  284,\n",
              "  5,\n",
              "  150,\n",
              "  4,\n",
              "  172,\n",
              "  112,\n",
              "  167,\n",
              "  2,\n",
              "  336,\n",
              "  385,\n",
              "  39,\n",
              "  4,\n",
              "  172,\n",
              "  4536,\n",
              "  1111,\n",
              "  17,\n",
              "  546,\n",
              "  38,\n",
              "  13,\n",
              "  447,\n",
              "  4,\n",
              "  192,\n",
              "  50,\n",
              "  16,\n",
              "  6,\n",
              "  147,\n",
              "  2025,\n",
              "  19,\n",
              "  14,\n",
              "  22,\n",
              "  4,\n",
              "  1920,\n",
              "  4613,\n",
              "  469,\n",
              "  4,\n",
              "  22,\n",
              "  71,\n",
              "  87,\n",
              "  12,\n",
              "  16,\n",
              "  43,\n",
              "  530,\n",
              "  38,\n",
              "  76,\n",
              "  15,\n",
              "  13,\n",
              "  1247,\n",
              "  4,\n",
              "  22,\n",
              "  17,\n",
              "  515,\n",
              "  17,\n",
              "  12,\n",
              "  16,\n",
              "  626,\n",
              "  18,\n",
              "  2,\n",
              "  5,\n",
              "  62,\n",
              "  386,\n",
              "  12,\n",
              "  8,\n",
              "  316,\n",
              "  8,\n",
              "  106,\n",
              "  5,\n",
              "  4,\n",
              "  2223,\n",
              "  5244,\n",
              "  16,\n",
              "  480,\n",
              "  66,\n",
              "  3785,\n",
              "  33,\n",
              "  4,\n",
              "  130,\n",
              "  12,\n",
              "  16,\n",
              "  38,\n",
              "  619,\n",
              "  5,\n",
              "  25,\n",
              "  124,\n",
              "  51,\n",
              "  36,\n",
              "  135,\n",
              "  48,\n",
              "  25,\n",
              "  1415,\n",
              "  33,\n",
              "  6,\n",
              "  22,\n",
              "  12,\n",
              "  215,\n",
              "  28,\n",
              "  77,\n",
              "  52,\n",
              "  5,\n",
              "  14,\n",
              "  407,\n",
              "  16,\n",
              "  82,\n",
              "  2,\n",
              "  8,\n",
              "  4,\n",
              "  107,\n",
              "  117,\n",
              "  5952,\n",
              "  15,\n",
              "  256,\n",
              "  4,\n",
              "  2,\n",
              "  7,\n",
              "  3766,\n",
              "  5,\n",
              "  723,\n",
              "  36,\n",
              "  71,\n",
              "  43,\n",
              "  530,\n",
              "  476,\n",
              "  26,\n",
              "  400,\n",
              "  317,\n",
              "  46,\n",
              "  7,\n",
              "  4,\n",
              "  2,\n",
              "  1029,\n",
              "  13,\n",
              "  104,\n",
              "  88,\n",
              "  4,\n",
              "  381,\n",
              "  15,\n",
              "  297,\n",
              "  98,\n",
              "  32,\n",
              "  2071,\n",
              "  56,\n",
              "  26,\n",
              "  141,\n",
              "  6,\n",
              "  194,\n",
              "  7486,\n",
              "  18,\n",
              "  4,\n",
              "  226,\n",
              "  22,\n",
              "  21,\n",
              "  134,\n",
              "  476,\n",
              "  26,\n",
              "  480,\n",
              "  5,\n",
              "  144,\n",
              "  30,\n",
              "  5535,\n",
              "  18,\n",
              "  51,\n",
              "  36,\n",
              "  28,\n",
              "  224,\n",
              "  92,\n",
              "  25,\n",
              "  104,\n",
              "  4,\n",
              "  226,\n",
              "  65,\n",
              "  16,\n",
              "  38,\n",
              "  1334,\n",
              "  88,\n",
              "  12,\n",
              "  16,\n",
              "  283,\n",
              "  5,\n",
              "  16,\n",
              "  4472,\n",
              "  113,\n",
              "  103,\n",
              "  32,\n",
              "  15,\n",
              "  16,\n",
              "  5345,\n",
              "  19,\n",
              "  178,\n",
              "  32],\n",
              " 1)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect a sample review and it's label\n",
        "sample_review=X_train[0]\n",
        "sample_label=y_train[0]\n",
        "\n",
        "print(f'Sample review (as integers) : {sample_review}')\n",
        "print(f'Sample label : {sample_label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_RFAKioo778",
        "outputId": "1dc461b4-2c55-44cf-c3ad-37f0359af8e8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample review (as integers) : [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "Sample label : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mappin of words index back to words(for understanding)\n",
        "word_index=imdb.get_word_index()\n",
        "word_index\n",
        "reverse_word_index= {value : key for key, value in word_index.items()}\n",
        "reverse_word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehE7Beknp6zv",
        "outputId": "fdb7bf57-e7eb-48d5-b25a-c8df1c925379"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{34701: 'fawn',\n",
              " 52006: 'tsukino',\n",
              " 52007: 'nunnery',\n",
              " 16816: 'sonja',\n",
              " 63951: 'vani',\n",
              " 1408: 'woods',\n",
              " 16115: 'spiders',\n",
              " 2345: 'hanging',\n",
              " 2289: 'woody',\n",
              " 52008: 'trawling',\n",
              " 52009: \"hold's\",\n",
              " 11307: 'comically',\n",
              " 40830: 'localized',\n",
              " 30568: 'disobeying',\n",
              " 52010: \"'royale\",\n",
              " 40831: \"harpo's\",\n",
              " 52011: 'canet',\n",
              " 19313: 'aileen',\n",
              " 52012: 'acurately',\n",
              " 52013: \"diplomat's\",\n",
              " 25242: 'rickman',\n",
              " 6746: 'arranged',\n",
              " 52014: 'rumbustious',\n",
              " 52015: 'familiarness',\n",
              " 52016: \"spider'\",\n",
              " 68804: 'hahahah',\n",
              " 52017: \"wood'\",\n",
              " 40833: 'transvestism',\n",
              " 34702: \"hangin'\",\n",
              " 2338: 'bringing',\n",
              " 40834: 'seamier',\n",
              " 34703: 'wooded',\n",
              " 52018: 'bravora',\n",
              " 16817: 'grueling',\n",
              " 1636: 'wooden',\n",
              " 16818: 'wednesday',\n",
              " 52019: \"'prix\",\n",
              " 34704: 'altagracia',\n",
              " 52020: 'circuitry',\n",
              " 11585: 'crotch',\n",
              " 57766: 'busybody',\n",
              " 52021: \"tart'n'tangy\",\n",
              " 14129: 'burgade',\n",
              " 52023: 'thrace',\n",
              " 11038: \"tom's\",\n",
              " 52025: 'snuggles',\n",
              " 29114: 'francesco',\n",
              " 52027: 'complainers',\n",
              " 52125: 'templarios',\n",
              " 40835: '272',\n",
              " 52028: '273',\n",
              " 52130: 'zaniacs',\n",
              " 34706: '275',\n",
              " 27631: 'consenting',\n",
              " 40836: 'snuggled',\n",
              " 15492: 'inanimate',\n",
              " 52030: 'uality',\n",
              " 11926: 'bronte',\n",
              " 4010: 'errors',\n",
              " 3230: 'dialogs',\n",
              " 52031: \"yomada's\",\n",
              " 34707: \"madman's\",\n",
              " 30585: 'dialoge',\n",
              " 52033: 'usenet',\n",
              " 40837: 'videodrome',\n",
              " 26338: \"kid'\",\n",
              " 52034: 'pawed',\n",
              " 30569: \"'girlfriend'\",\n",
              " 52035: \"'pleasure\",\n",
              " 52036: \"'reloaded'\",\n",
              " 40839: \"kazakos'\",\n",
              " 52037: 'rocque',\n",
              " 52038: 'mailings',\n",
              " 11927: 'brainwashed',\n",
              " 16819: 'mcanally',\n",
              " 52039: \"tom''\",\n",
              " 25243: 'kurupt',\n",
              " 21905: 'affiliated',\n",
              " 52040: 'babaganoosh',\n",
              " 40840: \"noe's\",\n",
              " 40841: 'quart',\n",
              " 359: 'kids',\n",
              " 5034: 'uplifting',\n",
              " 7093: 'controversy',\n",
              " 21906: 'kida',\n",
              " 23379: 'kidd',\n",
              " 52041: \"error'\",\n",
              " 52042: 'neurologist',\n",
              " 18510: 'spotty',\n",
              " 30570: 'cobblers',\n",
              " 9878: 'projection',\n",
              " 40842: 'fastforwarding',\n",
              " 52043: 'sters',\n",
              " 52044: \"eggar's\",\n",
              " 52045: 'etherything',\n",
              " 40843: 'gateshead',\n",
              " 34708: 'airball',\n",
              " 25244: 'unsinkable',\n",
              " 7180: 'stern',\n",
              " 52046: \"cervi's\",\n",
              " 40844: 'dnd',\n",
              " 11586: 'dna',\n",
              " 20598: 'insecurity',\n",
              " 52047: \"'reboot'\",\n",
              " 11037: 'trelkovsky',\n",
              " 52048: 'jaekel',\n",
              " 52049: 'sidebars',\n",
              " 52050: \"sforza's\",\n",
              " 17633: 'distortions',\n",
              " 52051: 'mutinies',\n",
              " 30602: 'sermons',\n",
              " 40846: '7ft',\n",
              " 52052: 'boobage',\n",
              " 52053: \"o'bannon's\",\n",
              " 23380: 'populations',\n",
              " 52054: 'chulak',\n",
              " 27633: 'mesmerize',\n",
              " 52055: 'quinnell',\n",
              " 10307: 'yahoo',\n",
              " 52057: 'meteorologist',\n",
              " 42577: 'beswick',\n",
              " 15493: 'boorman',\n",
              " 40847: 'voicework',\n",
              " 52058: \"ster'\",\n",
              " 22922: 'blustering',\n",
              " 52059: 'hj',\n",
              " 27634: 'intake',\n",
              " 5621: 'morally',\n",
              " 40849: 'jumbling',\n",
              " 52060: 'bowersock',\n",
              " 52061: \"'porky's'\",\n",
              " 16821: 'gershon',\n",
              " 40850: 'ludicrosity',\n",
              " 52062: 'coprophilia',\n",
              " 40851: 'expressively',\n",
              " 19500: \"india's\",\n",
              " 34710: \"post's\",\n",
              " 52063: 'wana',\n",
              " 5283: 'wang',\n",
              " 30571: 'wand',\n",
              " 25245: 'wane',\n",
              " 52321: 'edgeways',\n",
              " 34711: 'titanium',\n",
              " 40852: 'pinta',\n",
              " 178: 'want',\n",
              " 30572: 'pinto',\n",
              " 52065: 'whoopdedoodles',\n",
              " 21908: 'tchaikovsky',\n",
              " 2103: 'travel',\n",
              " 52066: \"'victory'\",\n",
              " 11928: 'copious',\n",
              " 22433: 'gouge',\n",
              " 52067: \"chapters'\",\n",
              " 6702: 'barbra',\n",
              " 30573: 'uselessness',\n",
              " 52068: \"wan'\",\n",
              " 27635: 'assimilated',\n",
              " 16116: 'petiot',\n",
              " 52069: 'most\\x85and',\n",
              " 3930: 'dinosaurs',\n",
              " 352: 'wrong',\n",
              " 52070: 'seda',\n",
              " 52071: 'stollen',\n",
              " 34712: 'sentencing',\n",
              " 40853: 'ouroboros',\n",
              " 40854: 'assimilates',\n",
              " 40855: 'colorfully',\n",
              " 27636: 'glenne',\n",
              " 52072: 'dongen',\n",
              " 4760: 'subplots',\n",
              " 52073: 'kiloton',\n",
              " 23381: 'chandon',\n",
              " 34713: \"effect'\",\n",
              " 27637: 'snugly',\n",
              " 40856: 'kuei',\n",
              " 9092: 'welcomed',\n",
              " 30071: 'dishonor',\n",
              " 52075: 'concurrence',\n",
              " 23382: 'stoicism',\n",
              " 14896: \"guys'\",\n",
              " 52077: \"beroemd'\",\n",
              " 6703: 'butcher',\n",
              " 40857: \"melfi's\",\n",
              " 30623: 'aargh',\n",
              " 20599: 'playhouse',\n",
              " 11308: 'wickedly',\n",
              " 1180: 'fit',\n",
              " 52078: 'labratory',\n",
              " 40859: 'lifeline',\n",
              " 1927: 'screaming',\n",
              " 4287: 'fix',\n",
              " 52079: 'cineliterate',\n",
              " 52080: 'fic',\n",
              " 52081: 'fia',\n",
              " 34714: 'fig',\n",
              " 52082: 'fmvs',\n",
              " 52083: 'fie',\n",
              " 52084: 'reentered',\n",
              " 30574: 'fin',\n",
              " 52085: 'doctresses',\n",
              " 52086: 'fil',\n",
              " 12606: 'zucker',\n",
              " 31931: 'ached',\n",
              " 52088: 'counsil',\n",
              " 52089: 'paterfamilias',\n",
              " 13885: 'songwriter',\n",
              " 34715: 'shivam',\n",
              " 9654: 'hurting',\n",
              " 299: 'effects',\n",
              " 52090: 'slauther',\n",
              " 52091: \"'flame'\",\n",
              " 52092: 'sommerset',\n",
              " 52093: 'interwhined',\n",
              " 27638: 'whacking',\n",
              " 52094: 'bartok',\n",
              " 8775: 'barton',\n",
              " 21909: 'frewer',\n",
              " 52095: \"fi'\",\n",
              " 6192: 'ingrid',\n",
              " 30575: 'stribor',\n",
              " 52096: 'approporiately',\n",
              " 52097: 'wobblyhand',\n",
              " 52098: 'tantalisingly',\n",
              " 52099: 'ankylosaurus',\n",
              " 17634: 'parasites',\n",
              " 52100: 'childen',\n",
              " 52101: \"jenkins'\",\n",
              " 52102: 'metafiction',\n",
              " 17635: 'golem',\n",
              " 40860: 'indiscretion',\n",
              " 23383: \"reeves'\",\n",
              " 57781: \"inamorata's\",\n",
              " 52104: 'brittannica',\n",
              " 7916: 'adapt',\n",
              " 30576: \"russo's\",\n",
              " 48246: 'guitarists',\n",
              " 10553: 'abbott',\n",
              " 40861: 'abbots',\n",
              " 17649: 'lanisha',\n",
              " 40863: 'magickal',\n",
              " 52105: 'mattter',\n",
              " 52106: \"'willy\",\n",
              " 34716: 'pumpkins',\n",
              " 52107: 'stuntpeople',\n",
              " 30577: 'estimate',\n",
              " 40864: 'ugghhh',\n",
              " 11309: 'gameplay',\n",
              " 52108: \"wern't\",\n",
              " 40865: \"n'sync\",\n",
              " 16117: 'sickeningly',\n",
              " 40866: 'chiara',\n",
              " 4011: 'disturbed',\n",
              " 40867: 'portmanteau',\n",
              " 52109: 'ineffectively',\n",
              " 82143: \"duchonvey's\",\n",
              " 37519: \"nasty'\",\n",
              " 1285: 'purpose',\n",
              " 52112: 'lazers',\n",
              " 28105: 'lightened',\n",
              " 52113: 'kaliganj',\n",
              " 52114: 'popularism',\n",
              " 18511: \"damme's\",\n",
              " 30578: 'stylistics',\n",
              " 52115: 'mindgaming',\n",
              " 46449: 'spoilerish',\n",
              " 52117: \"'corny'\",\n",
              " 34718: 'boerner',\n",
              " 6792: 'olds',\n",
              " 52118: 'bakelite',\n",
              " 27639: 'renovated',\n",
              " 27640: 'forrester',\n",
              " 52119: \"lumiere's\",\n",
              " 52024: 'gaskets',\n",
              " 884: 'needed',\n",
              " 34719: 'smight',\n",
              " 1297: 'master',\n",
              " 25905: \"edie's\",\n",
              " 40868: 'seeber',\n",
              " 52120: 'hiya',\n",
              " 52121: 'fuzziness',\n",
              " 14897: 'genesis',\n",
              " 12607: 'rewards',\n",
              " 30579: 'enthrall',\n",
              " 40869: \"'about\",\n",
              " 52122: \"recollection's\",\n",
              " 11039: 'mutilated',\n",
              " 52123: 'fatherlands',\n",
              " 52124: \"fischer's\",\n",
              " 5399: 'positively',\n",
              " 34705: '270',\n",
              " 34720: 'ahmed',\n",
              " 9836: 'zatoichi',\n",
              " 13886: 'bannister',\n",
              " 52127: 'anniversaries',\n",
              " 30580: \"helm's\",\n",
              " 52128: \"'work'\",\n",
              " 34721: 'exclaimed',\n",
              " 52129: \"'unfunny'\",\n",
              " 52029: '274',\n",
              " 544: 'feeling',\n",
              " 52131: \"wanda's\",\n",
              " 33266: 'dolan',\n",
              " 52133: '278',\n",
              " 52134: 'peacoat',\n",
              " 40870: 'brawny',\n",
              " 40871: 'mishra',\n",
              " 40872: 'worlders',\n",
              " 52135: 'protags',\n",
              " 52136: 'skullcap',\n",
              " 57596: 'dastagir',\n",
              " 5622: 'affairs',\n",
              " 7799: 'wholesome',\n",
              " 52137: 'hymen',\n",
              " 25246: 'paramedics',\n",
              " 52138: 'unpersons',\n",
              " 52139: 'heavyarms',\n",
              " 52140: 'affaire',\n",
              " 52141: 'coulisses',\n",
              " 40873: 'hymer',\n",
              " 52142: 'kremlin',\n",
              " 30581: 'shipments',\n",
              " 52143: 'pixilated',\n",
              " 30582: \"'00s\",\n",
              " 18512: 'diminishing',\n",
              " 1357: 'cinematic',\n",
              " 14898: 'resonates',\n",
              " 40874: 'simplify',\n",
              " 40875: \"nature'\",\n",
              " 40876: 'temptresses',\n",
              " 16822: 'reverence',\n",
              " 19502: 'resonated',\n",
              " 34722: 'dailey',\n",
              " 52144: '2\\x85',\n",
              " 27641: 'treize',\n",
              " 52145: 'majo',\n",
              " 21910: 'kiya',\n",
              " 52146: 'woolnough',\n",
              " 39797: 'thanatos',\n",
              " 35731: 'sandoval',\n",
              " 40879: 'dorama',\n",
              " 52147: \"o'shaughnessy\",\n",
              " 4988: 'tech',\n",
              " 32018: 'fugitives',\n",
              " 30583: 'teck',\n",
              " 76125: \"'e'\",\n",
              " 40881: 'doesn’t',\n",
              " 52149: 'purged',\n",
              " 657: 'saying',\n",
              " 41095: \"martians'\",\n",
              " 23418: 'norliss',\n",
              " 27642: 'dickey',\n",
              " 52152: 'dicker',\n",
              " 52153: \"'sependipity\",\n",
              " 8422: 'padded',\n",
              " 57792: 'ordell',\n",
              " 40882: \"sturges'\",\n",
              " 52154: 'independentcritics',\n",
              " 5745: 'tempted',\n",
              " 34724: \"atkinson's\",\n",
              " 25247: 'hounded',\n",
              " 52155: 'apace',\n",
              " 15494: 'clicked',\n",
              " 30584: \"'humor'\",\n",
              " 17177: \"martino's\",\n",
              " 52156: \"'supporting\",\n",
              " 52032: 'warmongering',\n",
              " 34725: \"zemeckis's\",\n",
              " 21911: 'lube',\n",
              " 52157: 'shocky',\n",
              " 7476: 'plate',\n",
              " 40883: 'plata',\n",
              " 40884: 'sturgess',\n",
              " 40885: \"nerds'\",\n",
              " 20600: 'plato',\n",
              " 34726: 'plath',\n",
              " 40886: 'platt',\n",
              " 52159: 'mcnab',\n",
              " 27643: 'clumsiness',\n",
              " 3899: 'altogether',\n",
              " 42584: 'massacring',\n",
              " 52160: 'bicenntinial',\n",
              " 40887: 'skaal',\n",
              " 14360: 'droning',\n",
              " 8776: 'lds',\n",
              " 21912: 'jaguar',\n",
              " 34727: \"cale's\",\n",
              " 1777: 'nicely',\n",
              " 4588: 'mummy',\n",
              " 18513: \"lot's\",\n",
              " 10086: 'patch',\n",
              " 50202: 'kerkhof',\n",
              " 52161: \"leader's\",\n",
              " 27644: \"'movie\",\n",
              " 52162: 'uncomfirmed',\n",
              " 40888: 'heirloom',\n",
              " 47360: 'wrangle',\n",
              " 52163: 'emotion\\x85',\n",
              " 52164: \"'stargate'\",\n",
              " 40889: 'pinoy',\n",
              " 40890: 'conchatta',\n",
              " 41128: 'broeke',\n",
              " 40891: 'advisedly',\n",
              " 17636: \"barker's\",\n",
              " 52166: 'descours',\n",
              " 772: 'lots',\n",
              " 9259: 'lotr',\n",
              " 9879: 'irs',\n",
              " 52167: 'lott',\n",
              " 40892: 'xvi',\n",
              " 34728: 'irk',\n",
              " 52168: 'irl',\n",
              " 6887: 'ira',\n",
              " 21913: 'belzer',\n",
              " 52169: 'irc',\n",
              " 27645: 'ire',\n",
              " 40893: 'requisites',\n",
              " 7693: 'discipline',\n",
              " 52961: 'lyoko',\n",
              " 11310: 'extend',\n",
              " 873: 'nature',\n",
              " 52170: \"'dickie'\",\n",
              " 40894: 'optimist',\n",
              " 30586: 'lapping',\n",
              " 3900: 'superficial',\n",
              " 52171: 'vestment',\n",
              " 2823: 'extent',\n",
              " 52172: 'tendons',\n",
              " 52173: \"heller's\",\n",
              " 52174: 'quagmires',\n",
              " 52175: 'miyako',\n",
              " 20601: 'moocow',\n",
              " 52176: \"coles'\",\n",
              " 40895: 'lookit',\n",
              " 52177: 'ravenously',\n",
              " 40896: 'levitating',\n",
              " 52178: 'perfunctorily',\n",
              " 30587: 'lookin',\n",
              " 40898: \"lot'\",\n",
              " 52179: 'lookie',\n",
              " 34870: 'fearlessly',\n",
              " 52181: 'libyan',\n",
              " 40899: 'fondles',\n",
              " 35714: 'gopher',\n",
              " 40901: 'wearying',\n",
              " 52182: \"nz's\",\n",
              " 27646: 'minuses',\n",
              " 52183: 'puposelessly',\n",
              " 52184: 'shandling',\n",
              " 31268: 'decapitates',\n",
              " 11929: 'humming',\n",
              " 40902: \"'nother\",\n",
              " 21914: 'smackdown',\n",
              " 30588: 'underdone',\n",
              " 40903: 'frf',\n",
              " 52185: 'triviality',\n",
              " 25248: 'fro',\n",
              " 8777: 'bothers',\n",
              " 52186: \"'kensington\",\n",
              " 73: 'much',\n",
              " 34730: 'muco',\n",
              " 22615: 'wiseguy',\n",
              " 27648: \"richie's\",\n",
              " 40904: 'tonino',\n",
              " 52187: 'unleavened',\n",
              " 11587: 'fry',\n",
              " 40905: \"'tv'\",\n",
              " 40906: 'toning',\n",
              " 14361: 'obese',\n",
              " 30589: 'sensationalized',\n",
              " 40907: 'spiv',\n",
              " 6259: 'spit',\n",
              " 7364: 'arkin',\n",
              " 21915: 'charleton',\n",
              " 16823: 'jeon',\n",
              " 21916: 'boardroom',\n",
              " 4989: 'doubts',\n",
              " 3084: 'spin',\n",
              " 53083: 'hepo',\n",
              " 27649: 'wildcat',\n",
              " 10584: 'venoms',\n",
              " 52191: 'misconstrues',\n",
              " 18514: 'mesmerising',\n",
              " 40908: 'misconstrued',\n",
              " 52192: 'rescinds',\n",
              " 52193: 'prostrate',\n",
              " 40909: 'majid',\n",
              " 16479: 'climbed',\n",
              " 34731: 'canoeing',\n",
              " 52195: 'majin',\n",
              " 57804: 'animie',\n",
              " 40910: 'sylke',\n",
              " 14899: 'conditioned',\n",
              " 40911: 'waddell',\n",
              " 52196: '3\\x85',\n",
              " 41188: 'hyperdrive',\n",
              " 34732: 'conditioner',\n",
              " 53153: 'bricklayer',\n",
              " 2576: 'hong',\n",
              " 52198: 'memoriam',\n",
              " 30592: 'inventively',\n",
              " 25249: \"levant's\",\n",
              " 20638: 'portobello',\n",
              " 52200: 'remand',\n",
              " 19504: 'mummified',\n",
              " 27650: 'honk',\n",
              " 19505: 'spews',\n",
              " 40912: 'visitations',\n",
              " 52201: 'mummifies',\n",
              " 25250: 'cavanaugh',\n",
              " 23385: 'zeon',\n",
              " 40913: \"jungle's\",\n",
              " 34733: 'viertel',\n",
              " 27651: 'frenchmen',\n",
              " 52202: 'torpedoes',\n",
              " 52203: 'schlessinger',\n",
              " 34734: 'torpedoed',\n",
              " 69876: 'blister',\n",
              " 52204: 'cinefest',\n",
              " 34735: 'furlough',\n",
              " 52205: 'mainsequence',\n",
              " 40914: 'mentors',\n",
              " 9094: 'academic',\n",
              " 20602: 'stillness',\n",
              " 40915: 'academia',\n",
              " 52206: 'lonelier',\n",
              " 52207: 'nibby',\n",
              " 52208: \"losers'\",\n",
              " 40916: 'cineastes',\n",
              " 4449: 'corporate',\n",
              " 40917: 'massaging',\n",
              " 30593: 'bellow',\n",
              " 19506: 'absurdities',\n",
              " 53241: 'expetations',\n",
              " 40918: 'nyfiken',\n",
              " 75638: 'mehras',\n",
              " 52209: 'lasse',\n",
              " 52210: 'visability',\n",
              " 33946: 'militarily',\n",
              " 52211: \"elder'\",\n",
              " 19023: 'gainsbourg',\n",
              " 20603: 'hah',\n",
              " 13420: 'hai',\n",
              " 34736: 'haj',\n",
              " 25251: 'hak',\n",
              " 4311: 'hal',\n",
              " 4892: 'ham',\n",
              " 53259: 'duffer',\n",
              " 52213: 'haa',\n",
              " 66: 'had',\n",
              " 11930: 'advancement',\n",
              " 16825: 'hag',\n",
              " 25252: \"hand'\",\n",
              " 13421: 'hay',\n",
              " 20604: 'mcnamara',\n",
              " 52214: \"mozart's\",\n",
              " 30731: 'duffel',\n",
              " 30594: 'haq',\n",
              " 13887: 'har',\n",
              " 44: 'has',\n",
              " 2401: 'hat',\n",
              " 40919: 'hav',\n",
              " 30595: 'haw',\n",
              " 52215: 'figtings',\n",
              " 15495: 'elders',\n",
              " 52216: 'underpanted',\n",
              " 52217: 'pninson',\n",
              " 27652: 'unequivocally',\n",
              " 23673: \"barbara's\",\n",
              " 52219: \"bello'\",\n",
              " 12997: 'indicative',\n",
              " 40920: 'yawnfest',\n",
              " 52220: 'hexploitation',\n",
              " 52221: \"loder's\",\n",
              " 27653: 'sleuthing',\n",
              " 32622: \"justin's\",\n",
              " 52222: \"'ball\",\n",
              " 52223: \"'summer\",\n",
              " 34935: \"'demons'\",\n",
              " 52225: \"mormon's\",\n",
              " 34737: \"laughton's\",\n",
              " 52226: 'debell',\n",
              " 39724: 'shipyard',\n",
              " 30597: 'unabashedly',\n",
              " 40401: 'disks',\n",
              " 2290: 'crowd',\n",
              " 10087: 'crowe',\n",
              " 56434: \"vancouver's\",\n",
              " 34738: 'mosques',\n",
              " 6627: 'crown',\n",
              " 52227: 'culpas',\n",
              " 27654: 'crows',\n",
              " 53344: 'surrell',\n",
              " 52229: 'flowless',\n",
              " 52230: 'sheirk',\n",
              " 40923: \"'three\",\n",
              " 52231: \"peterson'\",\n",
              " 52232: 'ooverall',\n",
              " 40924: 'perchance',\n",
              " 1321: 'bottom',\n",
              " 53363: 'chabert',\n",
              " 52233: 'sneha',\n",
              " 13888: 'inhuman',\n",
              " 52234: 'ichii',\n",
              " 52235: 'ursla',\n",
              " 30598: 'completly',\n",
              " 40925: 'moviedom',\n",
              " 52236: 'raddick',\n",
              " 51995: 'brundage',\n",
              " 40926: 'brigades',\n",
              " 1181: 'starring',\n",
              " 52237: \"'goal'\",\n",
              " 52238: 'caskets',\n",
              " 52239: 'willcock',\n",
              " 52240: \"threesome's\",\n",
              " 52241: \"mosque'\",\n",
              " 52242: \"cover's\",\n",
              " 17637: 'spaceships',\n",
              " 40927: 'anomalous',\n",
              " 27655: 'ptsd',\n",
              " 52243: 'shirdan',\n",
              " 21962: 'obscenity',\n",
              " 30599: 'lemmings',\n",
              " 30600: 'duccio',\n",
              " 52244: \"levene's\",\n",
              " 52245: \"'gorby'\",\n",
              " 25255: \"teenager's\",\n",
              " 5340: 'marshall',\n",
              " 9095: 'honeymoon',\n",
              " 3231: 'shoots',\n",
              " 12258: 'despised',\n",
              " 52246: 'okabasho',\n",
              " 8289: 'fabric',\n",
              " 18515: 'cannavale',\n",
              " 3537: 'raped',\n",
              " 52247: \"tutt's\",\n",
              " 17638: 'grasping',\n",
              " 18516: 'despises',\n",
              " 40928: \"thief's\",\n",
              " 8926: 'rapes',\n",
              " 52248: 'raper',\n",
              " 27656: \"eyre'\",\n",
              " 52249: 'walchek',\n",
              " 23386: \"elmo's\",\n",
              " 40929: 'perfumes',\n",
              " 21918: 'spurting',\n",
              " 52250: \"exposition'\\x85\",\n",
              " 52251: 'denoting',\n",
              " 34740: 'thesaurus',\n",
              " 40930: \"shoot'\",\n",
              " 49759: 'bonejack',\n",
              " 52253: 'simpsonian',\n",
              " 30601: 'hebetude',\n",
              " 34741: \"hallow's\",\n",
              " 52254: 'desperation\\x85',\n",
              " 34742: 'incinerator',\n",
              " 10308: 'congratulations',\n",
              " 52255: 'humbled',\n",
              " 5924: \"else's\",\n",
              " 40845: 'trelkovski',\n",
              " 52256: \"rape'\",\n",
              " 59386: \"'chapters'\",\n",
              " 52257: '1600s',\n",
              " 7253: 'martian',\n",
              " 25256: 'nicest',\n",
              " 52259: 'eyred',\n",
              " 9457: 'passenger',\n",
              " 6041: 'disgrace',\n",
              " 52260: 'moderne',\n",
              " 5120: 'barrymore',\n",
              " 52261: 'yankovich',\n",
              " 40931: 'moderns',\n",
              " 52262: 'studliest',\n",
              " 52263: 'bedsheet',\n",
              " 14900: 'decapitation',\n",
              " 52264: 'slurring',\n",
              " 52265: \"'nunsploitation'\",\n",
              " 34743: \"'character'\",\n",
              " 9880: 'cambodia',\n",
              " 52266: 'rebelious',\n",
              " 27657: 'pasadena',\n",
              " 40932: 'crowne',\n",
              " 52267: \"'bedchamber\",\n",
              " 52268: 'conjectural',\n",
              " 52269: 'appologize',\n",
              " 52270: 'halfassing',\n",
              " 57816: 'paycheque',\n",
              " 20606: 'palms',\n",
              " 52271: \"'islands\",\n",
              " 40933: 'hawked',\n",
              " 21919: 'palme',\n",
              " 40934: 'conservatively',\n",
              " 64007: 'larp',\n",
              " 5558: 'palma',\n",
              " 21920: 'smelling',\n",
              " 12998: 'aragorn',\n",
              " 52272: 'hawker',\n",
              " 52273: 'hawkes',\n",
              " 3975: 'explosions',\n",
              " 8059: 'loren',\n",
              " 52274: \"pyle's\",\n",
              " 6704: 'shootout',\n",
              " 18517: \"mike's\",\n",
              " 52275: \"driscoll's\",\n",
              " 40935: 'cogsworth',\n",
              " 52276: \"britian's\",\n",
              " 34744: 'childs',\n",
              " 52277: \"portrait's\",\n",
              " 3626: 'chain',\n",
              " 2497: 'whoever',\n",
              " 52278: 'puttered',\n",
              " 52279: 'childe',\n",
              " 52280: 'maywether',\n",
              " 3036: 'chair',\n",
              " 52281: \"rance's\",\n",
              " 34745: 'machu',\n",
              " 4517: 'ballet',\n",
              " 34746: 'grapples',\n",
              " 76152: 'summerize',\n",
              " 30603: 'freelance',\n",
              " 52283: \"andrea's\",\n",
              " 52284: '\\x91very',\n",
              " 45879: 'coolidge',\n",
              " 18518: 'mache',\n",
              " 52285: 'balled',\n",
              " 40937: 'grappled',\n",
              " 18519: 'macha',\n",
              " 21921: 'underlining',\n",
              " 5623: 'macho',\n",
              " 19507: 'oversight',\n",
              " 25257: 'machi',\n",
              " 11311: 'verbally',\n",
              " 21922: 'tenacious',\n",
              " 40938: 'windshields',\n",
              " 18557: 'paychecks',\n",
              " 3396: 'jerk',\n",
              " 11931: \"good'\",\n",
              " 34748: 'prancer',\n",
              " 21923: 'prances',\n",
              " 52286: 'olympus',\n",
              " 21924: 'lark',\n",
              " 10785: 'embark',\n",
              " 7365: 'gloomy',\n",
              " 52287: 'jehaan',\n",
              " 52288: 'turaqui',\n",
              " 20607: \"child'\",\n",
              " 2894: 'locked',\n",
              " 52289: 'pranced',\n",
              " 2588: 'exact',\n",
              " 52290: 'unattuned',\n",
              " 783: 'minute',\n",
              " 16118: 'skewed',\n",
              " 40940: 'hodgins',\n",
              " 34749: 'skewer',\n",
              " 52291: 'think\\x85',\n",
              " 38765: 'rosenstein',\n",
              " 52292: 'helmit',\n",
              " 34750: 'wrestlemanias',\n",
              " 16826: 'hindered',\n",
              " 30604: \"martha's\",\n",
              " 52293: 'cheree',\n",
              " 52294: \"pluckin'\",\n",
              " 40941: 'ogles',\n",
              " 11932: 'heavyweight',\n",
              " 82190: 'aada',\n",
              " 11312: 'chopping',\n",
              " 61534: 'strongboy',\n",
              " 41342: 'hegemonic',\n",
              " 40942: 'adorns',\n",
              " 41346: 'xxth',\n",
              " 34751: 'nobuhiro',\n",
              " 52298: 'capitães',\n",
              " 52299: 'kavogianni',\n",
              " 13422: 'antwerp',\n",
              " 6538: 'celebrated',\n",
              " 52300: 'roarke',\n",
              " 40943: 'baggins',\n",
              " 31270: 'cheeseburgers',\n",
              " 52301: 'matras',\n",
              " 52302: \"nineties'\",\n",
              " 52303: \"'craig'\",\n",
              " 12999: 'celebrates',\n",
              " 3383: 'unintentionally',\n",
              " 14362: 'drafted',\n",
              " 52304: 'climby',\n",
              " 52305: '303',\n",
              " 18520: 'oldies',\n",
              " 9096: 'climbs',\n",
              " 9655: 'honour',\n",
              " 34752: 'plucking',\n",
              " 30074: '305',\n",
              " 5514: 'address',\n",
              " 40944: 'menjou',\n",
              " 42592: \"'freak'\",\n",
              " 19508: 'dwindling',\n",
              " 9458: 'benson',\n",
              " 52307: 'white’s',\n",
              " 40945: 'shamelessness',\n",
              " 21925: 'impacted',\n",
              " 52308: 'upatz',\n",
              " 3840: 'cusack',\n",
              " 37567: \"flavia's\",\n",
              " 52309: 'effette',\n",
              " 34753: 'influx',\n",
              " 52310: 'boooooooo',\n",
              " 52311: 'dimitrova',\n",
              " 13423: 'houseman',\n",
              " 25259: 'bigas',\n",
              " 52312: 'boylen',\n",
              " 52313: 'phillipenes',\n",
              " 40946: 'fakery',\n",
              " 27658: \"grandpa's\",\n",
              " 27659: 'darnell',\n",
              " 19509: 'undergone',\n",
              " 52315: 'handbags',\n",
              " 21926: 'perished',\n",
              " 37778: 'pooped',\n",
              " 27660: 'vigour',\n",
              " 3627: 'opposed',\n",
              " 52316: 'etude',\n",
              " 11799: \"caine's\",\n",
              " 52317: 'doozers',\n",
              " 34754: 'photojournals',\n",
              " 52318: 'perishes',\n",
              " 34755: 'constrains',\n",
              " 40948: 'migenes',\n",
              " 30605: 'consoled',\n",
              " 16827: 'alastair',\n",
              " 52319: 'wvs',\n",
              " 52320: 'ooooooh',\n",
              " 34756: 'approving',\n",
              " 40949: 'consoles',\n",
              " 52064: 'disparagement',\n",
              " 52322: 'futureistic',\n",
              " 52323: 'rebounding',\n",
              " 52324: \"'date\",\n",
              " 52325: 'gregoire',\n",
              " 21927: 'rutherford',\n",
              " 34757: 'americanised',\n",
              " 82196: 'novikov',\n",
              " 1042: 'following',\n",
              " 34758: 'munroe',\n",
              " 52326: \"morita'\",\n",
              " 52327: 'christenssen',\n",
              " 23106: 'oatmeal',\n",
              " 25260: 'fossey',\n",
              " 40950: 'livered',\n",
              " 13000: 'listens',\n",
              " 76164: \"'marci\",\n",
              " 52330: \"otis's\",\n",
              " 23387: 'thanking',\n",
              " 16019: 'maude',\n",
              " 34759: 'extensions',\n",
              " 52332: 'ameteurish',\n",
              " 52333: \"commender's\",\n",
              " 27661: 'agricultural',\n",
              " 4518: 'convincingly',\n",
              " 17639: 'fueled',\n",
              " 54014: 'mahattan',\n",
              " 40952: \"paris's\",\n",
              " 52336: 'vulkan',\n",
              " 52337: 'stapes',\n",
              " 52338: 'odysessy',\n",
              " 12259: 'harmon',\n",
              " 4252: 'surfing',\n",
              " 23494: 'halloran',\n",
              " 49580: 'unbelieveably',\n",
              " 52339: \"'offed'\",\n",
              " 30607: 'quadrant',\n",
              " 19510: 'inhabiting',\n",
              " 34760: 'nebbish',\n",
              " 40953: 'forebears',\n",
              " 34761: 'skirmish',\n",
              " 52340: 'ocassionally',\n",
              " 52341: \"'resist\",\n",
              " 21928: 'impactful',\n",
              " 52342: 'spicier',\n",
              " 40954: 'touristy',\n",
              " 52343: \"'football'\",\n",
              " 40955: 'webpage',\n",
              " 52345: 'exurbia',\n",
              " 52346: 'jucier',\n",
              " 14901: 'professors',\n",
              " 34762: 'structuring',\n",
              " 30608: 'jig',\n",
              " 40956: 'overlord',\n",
              " 25261: 'disconnect',\n",
              " 82201: 'sniffle',\n",
              " 40957: 'slimeball',\n",
              " 40958: 'jia',\n",
              " 16828: 'milked',\n",
              " 40959: 'banjoes',\n",
              " 1237: 'jim',\n",
              " 52348: 'workforces',\n",
              " 52349: 'jip',\n",
              " 52350: 'rotweiller',\n",
              " 34763: 'mundaneness',\n",
              " 52351: \"'ninja'\",\n",
              " 11040: \"dead'\",\n",
              " 40960: \"cipriani's\",\n",
              " 20608: 'modestly',\n",
              " 52352: \"professor'\",\n",
              " 40961: 'shacked',\n",
              " 34764: 'bashful',\n",
              " 23388: 'sorter',\n",
              " 16120: 'overpowering',\n",
              " 18521: 'workmanlike',\n",
              " 27662: 'henpecked',\n",
              " 18522: 'sorted',\n",
              " 52354: \"jōb's\",\n",
              " 52355: \"'always\",\n",
              " 34765: \"'baptists\",\n",
              " 52356: 'dreamcatchers',\n",
              " 52357: \"'silence'\",\n",
              " 21929: 'hickory',\n",
              " 52358: 'fun\\x97yet',\n",
              " 52359: 'breakumentary',\n",
              " 15496: 'didn',\n",
              " 52360: 'didi',\n",
              " 52361: 'pealing',\n",
              " 40962: 'dispite',\n",
              " 25262: \"italy's\",\n",
              " 21930: 'instability',\n",
              " 6539: 'quarter',\n",
              " 12608: 'quartet',\n",
              " 52362: 'padmé',\n",
              " 52363: \"'bleedmedry\",\n",
              " 52364: 'pahalniuk',\n",
              " 52365: 'honduras',\n",
              " 10786: 'bursting',\n",
              " 41465: \"pablo's\",\n",
              " 52367: 'irremediably',\n",
              " 40963: 'presages',\n",
              " 57832: 'bowlegged',\n",
              " 65183: 'dalip',\n",
              " 6260: 'entering',\n",
              " 76172: 'newsradio',\n",
              " 54150: 'presaged',\n",
              " 27663: \"giallo's\",\n",
              " 40964: 'bouyant',\n",
              " 52368: 'amerterish',\n",
              " 18523: 'rajni',\n",
              " 30610: 'leeves',\n",
              " 34767: 'macauley',\n",
              " 612: 'seriously',\n",
              " 52369: 'sugercoma',\n",
              " 52370: 'grimstead',\n",
              " 52371: \"'fairy'\",\n",
              " 30611: 'zenda',\n",
              " 52372: \"'twins'\",\n",
              " 17640: 'realisation',\n",
              " 27664: 'highsmith',\n",
              " 7817: 'raunchy',\n",
              " 40965: 'incentives',\n",
              " 52374: 'flatson',\n",
              " 35097: 'snooker',\n",
              " 16829: 'crazies',\n",
              " 14902: 'crazier',\n",
              " 7094: 'grandma',\n",
              " 52375: 'napunsaktha',\n",
              " 30612: 'workmanship',\n",
              " 52376: 'reisner',\n",
              " 61306: \"sanford's\",\n",
              " 52377: '\\x91doña',\n",
              " 6108: 'modest',\n",
              " 19153: \"everything's\",\n",
              " 40966: 'hamer',\n",
              " 52379: \"couldn't'\",\n",
              " 13001: 'quibble',\n",
              " 52380: 'socking',\n",
              " 21931: 'tingler',\n",
              " 52381: 'gutman',\n",
              " 40967: 'lachlan',\n",
              " 52382: 'tableaus',\n",
              " 52383: 'headbanger',\n",
              " 2847: 'spoken',\n",
              " 34768: 'cerebrally',\n",
              " 23490: \"'road\",\n",
              " 21932: 'tableaux',\n",
              " 40968: \"proust's\",\n",
              " 40969: 'periodical',\n",
              " 52385: \"shoveller's\",\n",
              " 25263: 'tamara',\n",
              " 17641: 'affords',\n",
              " 3249: 'concert',\n",
              " 87955: \"yara's\",\n",
              " 52386: 'someome',\n",
              " 8424: 'lingering',\n",
              " 41511: \"abraham's\",\n",
              " 34769: 'beesley',\n",
              " 34770: 'cherbourg',\n",
              " 28624: 'kagan',\n",
              " 9097: 'snatch',\n",
              " 9260: \"miyazaki's\",\n",
              " 25264: 'absorbs',\n",
              " 40970: \"koltai's\",\n",
              " 64027: 'tingled',\n",
              " 19511: 'crossroads',\n",
              " 16121: 'rehab',\n",
              " 52389: 'falworth',\n",
              " 52390: 'sequals',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_review= ' '.join([reverse_word_index.get(i - 3, '?') for i in sample_review])\n",
        "decoded_review"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "_MSwg_3JqJ_V",
        "outputId": "6e816a89-048f-49a8-d0cb-480cace56baf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "max_len=500\n",
        "\n",
        "X_train=sequence.pad_sequences(X_train,maxlen=max_len)\n",
        "X_test=sequence.pad_sequences(X_test,maxlen=max_len)\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mbTfJXVrTcO",
        "outputId": "5cdc0bbc-f089-42b2-d606-deeda9df7c11"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,   19,  178,   32],\n",
              "       [   0,    0,    0, ...,   16,  145,   95],\n",
              "       [   0,    0,    0, ...,    7,  129,  113],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    4, 3586,    2],\n",
              "       [   0,    0,    0, ...,   12,    9,   23],\n",
              "       [   0,    0,    0, ...,  204,  131,    9]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enMhAW4vsZlE",
        "outputId": "30b80a6b-3f5c-421f-98f2-623b16530cb8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    1,   14,   22,   16,\n",
              "         43,  530,  973, 1622, 1385,   65,  458, 4468,   66, 3941,    4,\n",
              "        173,   36,  256,    5,   25,  100,   43,  838,  112,   50,  670,\n",
              "          2,    9,   35,  480,  284,    5,  150,    4,  172,  112,  167,\n",
              "          2,  336,  385,   39,    4,  172, 4536, 1111,   17,  546,   38,\n",
              "         13,  447,    4,  192,   50,   16,    6,  147, 2025,   19,   14,\n",
              "         22,    4, 1920, 4613,  469,    4,   22,   71,   87,   12,   16,\n",
              "         43,  530,   38,   76,   15,   13, 1247,    4,   22,   17,  515,\n",
              "         17,   12,   16,  626,   18,    2,    5,   62,  386,   12,    8,\n",
              "        316,    8,  106,    5,    4, 2223, 5244,   16,  480,   66, 3785,\n",
              "         33,    4,  130,   12,   16,   38,  619,    5,   25,  124,   51,\n",
              "         36,  135,   48,   25, 1415,   33,    6,   22,   12,  215,   28,\n",
              "         77,   52,    5,   14,  407,   16,   82,    2,    8,    4,  107,\n",
              "        117, 5952,   15,  256,    4,    2,    7, 3766,    5,  723,   36,\n",
              "         71,   43,  530,  476,   26,  400,  317,   46,    7,    4,    2,\n",
              "       1029,   13,  104,   88,    4,  381,   15,  297,   98,   32, 2071,\n",
              "         56,   26,  141,    6,  194, 7486,   18,    4,  226,   22,   21,\n",
              "        134,  476,   26,  480,    5,  144,   30, 5535,   18,   51,   36,\n",
              "         28,  224,   92,   25,  104,    4,  226,   65,   16,   38, 1334,\n",
              "         88,   12,   16,  283,    5,   16, 4472,  113,  103,   32,   15,\n",
              "         16, 5345,   19,  178,   32], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Train our Simple RNN\n",
        "model=Sequential()\n",
        "# Feature representation dimensions=128 we taken as our dataset is big\n",
        "model.add(Embedding(max_features,128,input_length=max_len)) # Embeding layers\n",
        "model.add(SimpleRNN(128,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "kqy7bCqhscsw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "THQ2YbngtUEk",
        "outputId": "d579c1bc-4a8a-44fc-c27c-1f2f2ce04535"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "RAif1ofducsT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of early stopping call backcall\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "earlystopping=EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)\n",
        "earlystopping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef8tkr29tXAZ",
        "outputId": "d4d570b0-6582-40b2-d5d5-be9ac0b2ca19"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.early_stopping.EarlyStopping at 0x7ebe38f3dc30>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Train the mmodel with early stopping\n",
        "model.fit(X_train,y_train,epochs=10,batch_size=32,validation_split=0.2,callbacks=[earlystopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4VxPnTzuBET",
        "outputId": "21d04803-25d9-47b2-e3b0-d97ad95ba48f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 244ms/step - accuracy: 0.5602 - loss: 5153.9824 - val_accuracy: 0.5984 - val_loss: 0.6617\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 240ms/step - accuracy: 0.6633 - loss: 5.0919 - val_accuracy: 0.6350 - val_loss: 0.6211\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 243ms/step - accuracy: 0.7351 - loss: 0.5378 - val_accuracy: 0.7302 - val_loss: 0.5292\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 242ms/step - accuracy: 0.8297 - loss: 0.4051 - val_accuracy: 0.7798 - val_loss: 0.4708\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 246ms/step - accuracy: 0.8745 - loss: 0.3010 - val_accuracy: 0.7716 - val_loss: 0.4908\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 243ms/step - accuracy: 0.9132 - loss: 0.2333 - val_accuracy: 0.8122 - val_loss: 0.4654\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 241ms/step - accuracy: 0.8382 - loss: 0.3905 - val_accuracy: 0.8082 - val_loss: 0.4839\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 244ms/step - accuracy: 0.9416 - loss: 0.1594 - val_accuracy: 0.8236 - val_loss: 0.4597\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 241ms/step - accuracy: 0.9601 - loss: 0.1193 - val_accuracy: 0.8218 - val_loss: 0.5471\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 243ms/step - accuracy: 0.9684 - loss: 0.0971 - val_accuracy: 0.8172 - val_loss: 0.5539\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ebe38f320e0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## save model file\n",
        "model.save('simple_rnn_imdb.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVlpHxNIuvE1",
        "outputId": "562058c7-adab-4637-ceec-0a112a017847"
      },
      "execution_count": 28,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prdiction.ipynb\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "Cw9Eig-zwrWz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the imdb dataset word index\n",
        "word_index=imdb.get_word_index()\n",
        "reverse_word_index={value: key for key , value in word_index.items()}"
      ],
      "metadata": {
        "id": "KSBgQHS-xBu2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the pretrained model with relu activation\n",
        "model=load_model('simple_rnn_imdb.h5')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "geMlL0I7xBrE",
        "outputId": "69526d44-89e6-4b78-f6d0-49b99fe47410"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │       \u001b[38;5;34m1,280,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)                     │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,313,027\u001b[0m (5.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,027</span> (5.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,313,025\u001b[0m (5.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,025</span> (5.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NqT0JNyxBoZ",
        "outputId": "7aea67f0-8df3-4e1b-e65a-cd7cb1bbe6dd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.05904543, -0.08319171, -0.06140236, ...,  0.11007243,\n",
              "         -0.01877811, -0.12541048],\n",
              "        [-0.0906449 , -0.00793815,  0.04789525, ..., -0.02904264,\n",
              "         -0.00560727, -0.01222532],\n",
              "        [-0.12829839,  0.10753977, -0.03699538, ..., -0.06895234,\n",
              "          0.00887247,  0.15954043],\n",
              "        ...,\n",
              "        [ 0.14169423, -0.12068132, -0.08153153, ...,  0.12056713,\n",
              "          0.04779708, -0.16940191],\n",
              "        [-0.07993961, -0.1082164 ,  0.05990629, ..., -0.06059893,\n",
              "         -0.04322733,  0.02996401],\n",
              "        [ 0.16807991,  0.07127607, -0.03711366, ...,  0.15163402,\n",
              "          0.16083112, -0.15402445]], dtype=float32),\n",
              " array([[ 0.08880959, -0.07670731, -0.00153941, ..., -0.01353471,\n",
              "          0.08414402,  0.06304327],\n",
              "        [ 0.08500733, -0.09132103,  0.08355312, ..., -0.12164538,\n",
              "          0.09354112, -0.03699722],\n",
              "        [-0.01788693,  0.09969223, -0.04997744, ...,  0.13665253,\n",
              "         -0.07086354, -0.05099045],\n",
              "        ...,\n",
              "        [ 0.07483798, -0.03741294,  0.07026294, ...,  0.16322072,\n",
              "         -0.17909072, -0.02137175],\n",
              "        [ 0.06240497, -0.02943009, -0.00602179, ..., -0.09260762,\n",
              "          0.07196561,  0.0432063 ],\n",
              "        [ 0.02929188,  0.041392  ,  0.1112113 , ..., -0.10946061,\n",
              "         -0.08195177, -0.11904312]], dtype=float32),\n",
              " array([[-0.01385223, -0.06582214, -0.0133452 , ..., -0.3308072 ,\n",
              "         -0.10232474, -0.00958337],\n",
              "        [-0.02238527,  0.18822446, -0.2657987 , ..., -0.01617488,\n",
              "          0.16372111,  0.07001743],\n",
              "        [-0.06322505, -0.15959848, -0.04473874, ..., -0.2665144 ,\n",
              "          0.04779971,  0.04332638],\n",
              "        ...,\n",
              "        [-0.00348064, -0.21629135, -0.02385135, ..., -0.03293809,\n",
              "         -0.02415136,  0.02050885],\n",
              "        [-0.01447598, -0.04591912,  0.25598195, ..., -0.03607127,\n",
              "         -0.07407032,  0.08878136],\n",
              "        [ 0.06655825,  0.02304664, -0.03539683, ..., -0.11344823,\n",
              "          0.01929055,  0.08850892]], dtype=float32),\n",
              " array([-0.01125121, -0.03268027,  0.00797371, -0.00039187, -0.01845121,\n",
              "        -0.01760994, -0.00962289,  0.00378366,  0.05642741, -0.01271281,\n",
              "         0.02090442, -0.01871392,  0.00033938, -0.0125887 , -0.02980526,\n",
              "        -0.00696245,  0.03254271,  0.03818031, -0.02493625,  0.04389348,\n",
              "        -0.01514905, -0.01136884, -0.03600435,  0.0262516 ,  0.00215751,\n",
              "        -0.02014194, -0.02011026, -0.03587514, -0.03069989, -0.02518755,\n",
              "        -0.02486377,  0.03514743, -0.03595872,  0.02931447, -0.01560657,\n",
              "        -0.00818567, -0.00454551,  0.01417572,  0.00140366, -0.02154727,\n",
              "        -0.00517729, -0.01754197,  0.0093782 , -0.00474315,  0.04043529,\n",
              "         0.02291809, -0.0249682 ,  0.03529608, -0.04295269,  0.02009383,\n",
              "        -0.05091426, -0.05222411,  0.04032452, -0.017512  , -0.01210087,\n",
              "         0.03635496, -0.03711527, -0.00616031, -0.0122122 , -0.02791401,\n",
              "         0.04719703,  0.0332874 , -0.02074604, -0.03132755, -0.02254062,\n",
              "        -0.01862738, -0.01848923, -0.01476091,  0.00532331,  0.00537555,\n",
              "         0.03359539, -0.00909868, -0.03479844,  0.03250873, -0.00363472,\n",
              "        -0.01997281, -0.02709032, -0.02681191, -0.01072478, -0.00381444,\n",
              "        -0.01112889,  0.04616014, -0.04118599, -0.01236878, -0.03550002,\n",
              "         0.00197474,  0.02665687, -0.02281658, -0.03433837,  0.03657696,\n",
              "         0.02340128,  0.01340776,  0.01183962, -0.0024433 ,  0.04093114,\n",
              "         0.00354878, -0.01779332, -0.00557523,  0.01600563,  0.00261748,\n",
              "        -0.0266403 , -0.01127777,  0.0219546 , -0.01281176, -0.01765064,\n",
              "        -0.01106203, -0.02214312,  0.04012148,  0.00404068,  0.02823424,\n",
              "         0.00493328, -0.04264616,  0.04979435,  0.04059349,  0.02811039,\n",
              "         0.00494026, -0.02463341, -0.0238836 , -0.01879534, -0.05573516,\n",
              "        -0.00538526,  0.04370292, -0.03125394, -0.0341902 ,  0.04754932,\n",
              "         0.0155616 ,  0.04567942,  0.03203606], dtype=float32),\n",
              " array([[-7.98945874e-03],\n",
              "        [ 2.12440491e-01],\n",
              "        [ 1.22386718e-03],\n",
              "        [ 6.97679818e-02],\n",
              "        [ 6.56313151e-02],\n",
              "        [ 1.25888642e-02],\n",
              "        [-2.07251117e-01],\n",
              "        [-2.11255476e-02],\n",
              "        [-1.89146578e-01],\n",
              "        [-1.24333650e-02],\n",
              "        [-1.25253692e-01],\n",
              "        [ 1.21583664e+00],\n",
              "        [ 6.25694543e-02],\n",
              "        [-1.21346883e-01],\n",
              "        [-4.21217307e-02],\n",
              "        [ 1.71398491e-01],\n",
              "        [ 1.80020466e-01],\n",
              "        [ 2.31131181e-01],\n",
              "        [ 1.71519175e-01],\n",
              "        [-1.53518856e-01],\n",
              "        [-2.71258559e-02],\n",
              "        [ 1.92719072e-01],\n",
              "        [-1.65320590e-01],\n",
              "        [-1.24804080e-01],\n",
              "        [ 1.68132763e-02],\n",
              "        [ 1.66896686e-01],\n",
              "        [ 4.33530003e-01],\n",
              "        [-1.59830973e-01],\n",
              "        [ 1.85685009e-01],\n",
              "        [ 1.60019234e-01],\n",
              "        [ 6.72792941e-02],\n",
              "        [-8.03013984e-03],\n",
              "        [ 1.21404834e-01],\n",
              "        [ 6.42080605e-03],\n",
              "        [ 6.08741231e-02],\n",
              "        [ 1.60309657e-01],\n",
              "        [-9.00211096e-01],\n",
              "        [ 7.23376796e-02],\n",
              "        [-1.66989341e-01],\n",
              "        [-5.14161102e-02],\n",
              "        [-1.76475450e-01],\n",
              "        [-2.41447147e-02],\n",
              "        [ 1.16015576e-01],\n",
              "        [ 1.63914889e-01],\n",
              "        [-1.26092019e-03],\n",
              "        [-1.06858686e-01],\n",
              "        [ 3.27710062e-01],\n",
              "        [-4.25483435e-02],\n",
              "        [ 1.06616229e-01],\n",
              "        [ 8.90165940e-02],\n",
              "        [-7.12476015e-01],\n",
              "        [-1.00801319e-01],\n",
              "        [ 1.44698948e-01],\n",
              "        [ 1.09562963e-01],\n",
              "        [ 1.50284529e-01],\n",
              "        [-2.38585815e-01],\n",
              "        [ 7.65557140e-02],\n",
              "        [ 7.30870783e-01],\n",
              "        [-4.72786836e-02],\n",
              "        [-9.62892547e-02],\n",
              "        [-2.24425182e-01],\n",
              "        [-3.26901115e-02],\n",
              "        [-1.79935050e+00],\n",
              "        [ 5.93597032e-02],\n",
              "        [-1.58386305e-01],\n",
              "        [ 8.33358318e-02],\n",
              "        [-1.19743332e-01],\n",
              "        [-4.91356524e-03],\n",
              "        [-3.06252390e-04],\n",
              "        [ 1.44999668e-01],\n",
              "        [-9.03948098e-02],\n",
              "        [ 1.21534035e-01],\n",
              "        [ 1.56501532e-01],\n",
              "        [ 1.53431967e-01],\n",
              "        [-1.28312573e-01],\n",
              "        [ 1.64045826e-01],\n",
              "        [-1.91126212e-01],\n",
              "        [ 1.37501135e-01],\n",
              "        [ 2.71354705e-01],\n",
              "        [-3.33706662e-02],\n",
              "        [ 1.68193147e-01],\n",
              "        [-2.41513222e-01],\n",
              "        [-1.83065459e-01],\n",
              "        [ 1.74409583e-01],\n",
              "        [ 8.98466818e-03],\n",
              "        [ 9.54406038e-02],\n",
              "        [ 5.30349463e-02],\n",
              "        [ 2.36650631e-01],\n",
              "        [ 1.37301490e-01],\n",
              "        [-7.21356971e-03],\n",
              "        [ 1.03275338e-03],\n",
              "        [ 2.33630434e-01],\n",
              "        [ 1.96460798e-01],\n",
              "        [ 1.90810487e-01],\n",
              "        [-6.02823459e-02],\n",
              "        [ 2.47240871e-01],\n",
              "        [ 2.04305559e-01],\n",
              "        [-5.82690276e-02],\n",
              "        [ 7.51792118e-02],\n",
              "        [-1.90651044e-01],\n",
              "        [-2.08136782e-01],\n",
              "        [-1.24062233e-01],\n",
              "        [ 8.34111869e-02],\n",
              "        [ 9.32628885e-02],\n",
              "        [ 2.64046878e-01],\n",
              "        [-1.09584324e-01],\n",
              "        [-1.26772419e-01],\n",
              "        [-4.60434444e-02],\n",
              "        [ 1.80498883e-01],\n",
              "        [-2.54735351e-02],\n",
              "        [ 1.48274779e-01],\n",
              "        [ 1.68540224e-01],\n",
              "        [-2.01486290e-01],\n",
              "        [-2.37193201e-02],\n",
              "        [ 4.03203256e-02],\n",
              "        [ 8.02048594e-02],\n",
              "        [ 5.48561402e-02],\n",
              "        [ 1.19874328e-01],\n",
              "        [-1.40668884e-01],\n",
              "        [-3.95298749e-02],\n",
              "        [-4.68112677e-02],\n",
              "        [ 1.31609574e-01],\n",
              "        [ 1.06679508e-02],\n",
              "        [-1.01022720e-01],\n",
              "        [ 4.29579765e-02],\n",
              "        [ 1.30582348e-01],\n",
              "        [ 7.75371715e-02],\n",
              "        [-2.20638290e-02]], dtype=float32),\n",
              " array([0.6353613], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2 Helper Function\n",
        "# function to decode reviews\n",
        "def decode_review(encoded_review):\n",
        "  return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n",
        "\n",
        "#Function to preprocess user input\n",
        "def preprocess_text(text):\n",
        "  words=text.lower().split()\n",
        "  encoded_review=[word_index.get(word,2) + 3 for word in words]\n",
        "  padded_review=sequence.pad_sequences([encoded_review],maxlen=500)\n",
        "  return padded_review"
      ],
      "metadata": {
        "id": "jPEoJeBxxBlx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Prediction Function\n",
        "def predict_sentiment(review):\n",
        "  preproceseed_input=preprocess_text(review)\n",
        "\n",
        "  prediction=model.predict(preproceseed_input)\n",
        "\n",
        "  sentiment= 'Positive' if prediction[0][0] > 0.5 else 'Negative'\n",
        "\n",
        "  return sentiment, prediction[0][0]"
      ],
      "metadata": {
        "id": "TYkfjZU8xBi-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step 4 :- User input and prediction\n",
        "#example review for prediction\n",
        "example_review='This movie was fantastic! The acting was great and the plot was thrilling.'\n",
        "\n",
        "sentiment,score=predict_sentiment(example_review)\n",
        "\n",
        "print(f'Review : {example_review}')\n",
        "print(f'Sentiment : {sentiment}')\n",
        "print(f'Prediction score : {score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu2G6eaZxBgW",
        "outputId": "515874da-f585-475a-cc51-9746b5d15437"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "Review : This movie was fantastic! The acting was great and the plot was thrilling.\n",
            "Sentiment : Positive\n",
            "Prediction score : 0.8699265122413635\n"
          ]
        }
      ]
    }
  ]
}